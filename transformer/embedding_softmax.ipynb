{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c52b0c42",
   "metadata": {},
   "source": [
    "# 文本 embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd9ffcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "562e9934",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, embed_dim, vocab):\n",
    "        \"\"\"\n",
    "        Embeddings and Softmax\n",
    "        与其他序列转导模型类似，使用学习好的嵌入层将输入token和输出token转换为向量.\n",
    "        使用线性变换和 softmax 函数将decoder输出转换为预测的下一个token概率。\n",
    "        :param embed_dim: (int) embedding后词向量维度\n",
    "        :param vocab: (Tensor)输入词向量\n",
    "        \"\"\"\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, embed_dim)\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 此处的缩放是为了让 embeding 后的尺度在一个合适的范围内\n",
    "        return self.lut(x) * math.sqrt(self.embed_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b0e57d",
   "metadata": {},
   "source": [
    "# 测试例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5414e875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1758, -1.4697,  1.4782, -0.5715, -0.7141],\n",
      "        [-1.0198,  0.0553,  0.2517,  0.2503,  0.4059],\n",
      "        [ 0.6559, -0.7183,  0.0511, -1.0875,  0.4223],\n",
      "        [ 0.0113,  0.2559, -1.4108, -1.5821,  0.1742]], requires_grad=True)\n",
      "word1:\n",
      "tensor([[ 0.1758, -1.4697,  1.4782, -0.5715, -0.7141],\n",
      "        [-1.0198,  0.0553,  0.2517,  0.2503,  0.4059],\n",
      "        [ 0.6559, -0.7183,  0.0511, -1.0875,  0.4223]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "word2:\n",
      "tensor([[ 0.0113,  0.2559, -1.4108, -1.5821,  0.1742],\n",
      "        [-1.0198,  0.0553,  0.2517,  0.2503,  0.4059],\n",
      "        [ 0.6559, -0.7183,  0.0511, -1.0875,  0.4223]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\"\"\"\n",
    "首先 word1 和 word2 表示的两句话，这里的0，1，2，3 表示单词的索引，用过索引来表示对应的单词\n",
    "embeding 的形状是 (4,5),这里 4 是因为例子中单词共有 4 个对应一个单词一行，\n",
    "至于 5 这个维度其实是需要调的，词汇多关系复杂维度低不足以表达太高容易过拟合\n",
    "\"\"\"\n",
    "word1 = torch.LongTensor([0, 1, 2])\n",
    "word2 = torch.LongTensor([3, 1, 2])\n",
    "embedding = torch.nn.Embedding(4, 5)\n",
    "print(embedding.weight)\n",
    "print('word1:')\n",
    "print(embedding(word1))\n",
    "print('word2:')\n",
    "print(embedding(word2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a73889c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b6d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d17ea5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537d053f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9955292c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5baa946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26d4d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae3b928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b1ea2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9deffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2033e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36edc0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_test",
   "language": "python",
   "name": "nlp_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
